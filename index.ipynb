{"metadata":{"kernelspec":{"name":"python3","display_name":"Python 3 (ipykernel)","language":"python"},"language_info":{"name":"python","version":"3.10.19","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat_minor":5,"nbformat":4,"cells":[{"id":"3703d9d5-283c-4c17-9e84-adf2cbab8a73","cell_type":"markdown","source":"# Sproochmaschinn Lab (TTS + STT)\n\nThis notebook uses the Sproochmaschinn API.\n\n**What you edit:** small values like `MODEL`, `TEXT`, and filenames.  \n**What you don't touch:** the helper functions.\n\n---\n","metadata":{}},{"id":"09c062d3-2dc9-4682-977b-600a04831a8a","cell_type":"code","source":"import time, base64\nimport requests\n\nBASE_URL = \"https://sproochmaschinn.lu\"\n\n# Create a session (expires after inactivity)\nSESSION_ID = requests.post(f\"{BASE_URL}/api/session\").json()[\"session_id\"]\nprint(\"SESSION_ID:\", SESSION_ID)\n\ndef wait_result(request_id, poll_s=1.0, timeout_s=1800):\n    t0 = time.time()\n    while True:\n        r = requests.get(f\"{BASE_URL}/api/result/{request_id}\").json()\n        if r.get(\"status\") == \"completed\":\n            return r\n        if time.time() - t0 > timeout_s:\n            raise TimeoutError(\"Timed out waiting for result\")\n        time.sleep(poll_s)\n\ndef save_wav_from_base64(b64_data, outfile):\n    with open(outfile, \"wb\") as f:\n        f.write(base64.b64decode(b64_data))\n","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"id":"91654631-9749-416f-8742-5c8c7e376a93","cell_type":"markdown","source":"---\n\n# Part A — Text-to-Speech (TTS)\n\nEdit the **three** variables below:\n- `TEXT` (Luxembourgish text)\n- `MODEL` (`\"claude\"`, `\"max\"`, or `\"maxine\"`)\n- `OUTFILE` (where to save the wav)\n\nThen run the cell.\n\n---\n","metadata":{}},{"id":"234250a5-6109-4f49-82d6-1268ad8a20f3","cell_type":"code","source":"\nTEXT = \"Moien, wéi geet et?\"\nMODEL = \"maxine\"     # \"claude\" | \"max\" | \"maxine\"\nOUTFILE = \"tts.wav\"\n\nreq = requests.post(\n    f\"{BASE_URL}/api/tts/{SESSION_ID}\",\n    json={\"text\": TEXT, \"model\": MODEL}\n).json()\n\nres = wait_result(req[\"request_id\"], poll_s=1.0, timeout_s=300)\nb64 = res[\"result\"][\"data\"]\n\nsave_wav_from_base64(b64, OUTFILE)\nprint(\"Saved:\", OUTFILE)\n\nfrom IPython.display import Audio, display\ndisplay(Audio(OUTFILE))\n","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"id":"8060a7e0-5f19-44ae-9dc0-dd50d3c2e770","cell_type":"markdown","source":"---\n\n# Part B — Speech-to-Text (STT)\n\nYou have two choices:\n\n## Option 1: Use a sample file from the repo\nPut wav files in a folder called `data/` (for Binder), then set:\n- `INPUT_FILE = \"data/sample1.wav\"`\n\n## Option 2: Upload a file manually\nDrag and drop your file into the file menu on the left side of the screen, then set:\n- `INPUT_FILE = \"whatever_you_uploaded.wav\"`\n\nYou can also toggle diarization (speaker identification).\n\n---\n","metadata":{}},{"id":"d325ce6f-da65-46e8-8f32-de5ec31d5ec0","cell_type":"code","source":"INPUT_FILE = \"data/audio1.wav\"   # e.g. \"data/audio1.wav\" or \"my_audio.wav\"\nENABLE_SPEAKER_ID = True          # True / False\n\nwith open(INPUT_FILE, \"rb\") as f:\n    req = requests.post(\n        f\"{BASE_URL}/api/stt/{SESSION_ID}\",\n        files={\"audio\": f},\n        data={\"enable_speaker_identification\": str(ENABLE_SPEAKER_ID).lower()}\n    ).json()\n\nres = wait_result(req[\"request_id\"], poll_s=1.0, timeout_s=1800)\n\nprint(\"\\nTRANSCRIPT:\\n\")\nprint(res[\"result\"].get(\"text\", \"\"))\n","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"id":"a745744b-c06d-4863-88b6-c1c905da21af","cell_type":"markdown","source":"---\n\n# Part C — Exports (optional)\n\nEdit the options and run to generate files:\n- `transcript.txt`\n- `transcript_sentence.txt` (or word/segment)\n- `transcript.srt`\n\n---\n","metadata":{}},{"id":"7149ad76-f692-4715-a1b5-4c9f27d75558","cell_type":"code","source":"TIMESTAMPS_LEVEL = \"sentence\"     # \"word\" | \"sentence\" | \"segment\"\nINCLUDE_SPEAKERS = True           # True / False\nINCLUDE_CONFIDENCE = True         # True / False\nDO_SRT = True                     # True / False\n\n# Uses the most recent STT request from the previous cell:\nrequest_id = req[\"request_id\"]\nbase = f\"{BASE_URL}/api/result/{request_id}/export\"\n\ndef download_text(url, params, outfile):\n    r = requests.get(url, params=params)\n    ct = (r.headers.get(\"content-type\") or \"\").lower()\n    content = r.json().get(\"content\", \"\") if \"application/json\" in ct else r.text\n    with open(outfile, \"w\", encoding=\"utf-8\") as f:\n        f.write(content)\n    print(\"Saved:\", outfile)\n\ndownload_text(\n    f\"{base}/plaintext\",\n    {\"include_speakers\": str(INCLUDE_SPEAKERS).lower()},\n    \"transcript.txt\"\n)\n\ndownload_text(\n    f\"{base}/timestamps\",\n    {\n        \"level\": TIMESTAMPS_LEVEL,\n        \"include_speakers\": str(INCLUDE_SPEAKERS).lower(),\n        \"include_confidence\": str(INCLUDE_CONFIDENCE).lower(),\n    },\n    f\"transcript_{TIMESTAMPS_LEVEL}.txt\"\n)\n\nif DO_SRT:\n    download_text(\n        f\"{base}/srt\",\n        {\"include_speakers\": str(INCLUDE_SPEAKERS).lower()},\n        \"transcript.srt\"\n    )\n","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"id":"6842f3bb-0707-4ffa-a0a7-0aae6d275858","cell_type":"code","source":"","metadata":{"trusted":true},"outputs":[],"execution_count":null}]}